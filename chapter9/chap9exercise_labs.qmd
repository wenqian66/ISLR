---
title: "Untitled"
format: pdf
editor: visual
---
```{r}
install.packages("e1071")
library(e1071)
```

#########labs

## 9.6.1 Support Vector Classifer
#checking whether the classes are linearly separable
```{r}
set.seed(1)
x <- matrix(rnorm(20 * 2), ncol = 2)
y <- c(rep(-1, 10), rep(1, 10))
x[y == 1, ] <- x[y == 1, ] + 1
plot(x, col = (3 - y))
```

##fit the classifer
```{r}
dat <- data.frame(x = x, y = as.factor(y))
svmfit <- svm(y ~ ., data = dat, kernel = "linear",
              cost = 10, scale = FALSE)
```

```{r}
plot(svmfit, dat)
```


```{r}
svmfit$index
```

#there are seven support vectors

```{r}
summary(svmfit)
```

```{r}
svmfit <- svm(y ~ ., data = dat, kernel = "linear",
              cost = 0.1, scale = FALSE)
plot(svmfit, dat)
svmfit$index
```


#Now that a smaller value of the cost parameter is being used, we obtain a larger number of support vectors, because the margin is now wider.


#perform cross validation

```{r}
set.seed(1)
tune.out <- tune(svm, y ~ ., data = dat, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
```

```{r}
summary(tune.out)
```


#cost = 0.1 results in the lowest cross-validation error rate

```{r}
bestmod <- tune.out$best.model
summary(bestmod)
```

#generating a test data set.
```{r}
xtest <- matrix(rnorm(20 * 2), ncol = 2)
ytest <- sample(c(-1, 1), 20, rep = TRUE)
xtest[ytest == 1, ] <- xtest[ytest == 1, ] + 1
testdat <- data.frame(x = xtest, y = as.factor(ytest))
```

# predict the class labels of these test observations

```{r}
ypred <- predict(bestmod, testdat)
table(predict = ypred, truth = testdat$y)
```
# What if we had instead used cost = 0.01?

```{r}
svmfit <- svm(y ~ ., data = dat, kernel = "linear",
              cost = .01, scale = FALSE)
ypred <- predict(svmfit, testdat)
table(predict = ypred, truth = testdat$y)
```

# three additional observations are misclassifed

# further separate the two classes in our simulated data so that they are linearly separable

```{r}
x[y == 1, ] <- x[y == 1, ] + 0.5
plot(x, col = (y + 5) / 2, pch = 19)
```
```{r}
dat <- data.frame(x = x, y = as.factor(y))
svmfit <- svm(y ~ ., data = dat, kernel = "linear",
              cost = 1e5)
summary(svmfit)
```

#only three support vectors were used

#It seems likely that this model will perform poorly on test data.


```{r}
svmfit <- svm(y ~ ., data = dat, kernel = "linear", cost = 1)
summary(svmfit)
plot(svmfit, dat)
```
#9.6.2 Support Vector Machine
```{r}
set.seed(1)
x <- matrix(rnorm(200 * 2), ncol = 2)
x[1:100, ] <- x[1:100, ] + 2
x[101:150, ] <- x[101:150, ] - 2
y <- c(rep(1, 150), rep(2, 50))
dat <- data.frame(x = x, y = as.factor(y))
```

```{r}
plot(x, col = y)
```

# fit the training data using the svm() function with a radial kernel and γ = 1:

```{r}
train <- sample(200, 100)
svmfit <- svm(y ~ ., data = dat[train, ], kernel = "radial",
              gamma = 1, cost = 1)
plot(svmfit, dat[train, ])
```

```{r}
summary(svmfit)
```
# seems to be at risk of overftting the data.

```{r}
svmfit <- svm(y ~ ., data = dat[train, ], kernel = "radial",
              gamma = 1, cost = 1e5)
plot(svmfit, dat[train, ])
```


#perform cross-validation using tune() to select the best choice of γ and cost for an SVM with a radial kernel

```{r}
set.seed(1)
tune.out <- tune(svm, y ~ ., data = dat[train, ],
                 kernel = "radial",
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000),
                               gamma = c(0.5, 1, 2, 3, 4)
                               ) ) 
summary(tune.out)
```



```{r}
table(
  true = dat[-train, "y"],
  pred = predict(
    tune.out$best.model, newdata = dat[-train, ]
    ) )
```
#12 % of test observations are misclassifed by this SVM

#9.6.3 ROC Curves
```{r}
library(ROCR)
rocplot <- function(pred, truth, ...) {
  predob <- prediction(pred, truth)
  perf <- performance(predob, "tpr", "fpr") 
  plot(perf, ...)
}
```

```{r}
svmfit.opt <- svm(y ~ ., data = dat[train, ],
                  kernel = "radial", gamma = 2, cost = 1,
                  decision.values = T)
fitted <- attributes(
  predict(svmfit.opt, dat[train, ], decision.values = TRUE)
  )$decision.values
```


```{r}
par(mfrow = c(1, 2))
rocplot(-fitted, dat[train, "y"], main = "Training Data")
```

#SVM appears to be producing accurate predictions. By increasing γ we can produce a more fexible ft and generate further improvements in accuracy

```{r}
par(mfrow = c(1, 2))
rocplot(-fitted, dat[train, "y"], main = "Training Data")
svmfit.flex <- svm(y ~ ., data = dat[train, ],
                   kernel = "radial", gamma = 50, cost = 1,
                   decision.values = T)

fitted <- attributes(
  predict(svmfit.flex, dat[train, ], decision.values = T)
  )$decision.values

rocplot(-fitted, dat[train, "y"], add = T, col = "red")
```
#We are really more interested in the level of prediction accuracy on the test data.
#model with γ = 2 appears to provide the most accurate results.

```{r}
fitted <- attributes(
  predict(svmfit.opt, dat[-train, ], decision.values = T)
  )$decision.values

rocplot(-fitted, dat[-train, "y"], main = "Test Data") 
fitted <- attributes(
  predict(svmfit.flex, dat[-train, ], decision.values = T)
  )$decision.values

rocplot(-fitted, dat[-train, "y"], add = T, col = "red")
```


#9.6.4 SVM with Multiple Classes
```{r}
set.seed(1)
x <- rbind(x, matrix(rnorm(50 * 2), ncol = 2)) #entries for 50 observations, each with two features. #appends this new matrix to the existing x matrix
y <- c(y, rep(0, 50)) #creates a vector of 50 zeros
x[y == 0, 2] <- x[y == 0, 2] + 2
dat <- data.frame(x = x, y = as.factor(y))
par(mfrow = c(1, 1))
plot(x, col = (y + 1))
```



```{r}
svmfit <- svm(y ~ ., data = dat, kernel = "radial",
              cost = 10, gamma = 1)
plot(svmfit, dat)
```
#9.6.5 Application to Gene Expression Data
```{r}
library(ISLR2)
names(Khan)

dim(Khan$xtrain)

dim(Khan$xtest)

length(Khan$ytrain)

length(Khan$ytest)
```
```{r}
table(Khan$ytrain)
table(Khan$ytest)
```
```{r}
dat <- data.frame(
  x = Khan$xtrain,
  y = as.factor(Khan$ytrain)
)

out <- svm(y ~ ., data = dat, kernel = "linear",
           cost = 10)

summary(out)
```



```{r}
table(out$fitted, dat$y)
```



```{r}
dat.te <- data.frame(
  x = Khan$xtest,
  y = as.factor(Khan$ytest))

pred.te <- predict(out, newdata = dat.te)
table(pred.te, dat.te$y)
```
##################
#9.7 Applied Exercises
#4.

```{r}
set.seed(1)
x <- matrix(rnorm(100 * 2), ncol = 2)
x[1:20, ] <- x[1:20, ] + 1
x[20:40, ] <- x[20:40, ] - 2
y <- c(rep(1, 50), rep(2, 50))
dat <- data.frame(x = x, y = as.factor(y))
```

```{r}
plot(x, col = y)
```
#a polynomial kernel
```{r}
train <- sample(100, 50)
svmfit <- svm(y ~ ., data = dat[train, ], kernel = "poly",
              degree = 2)

set.seed(1)
tune.out <- tune(svm, y ~ ., data = dat[train, ],
                 kernel = "poly",
                 ranges = list(degree = c(1, 2, 3, 4)
) )
summary(tune.out)
```
```{r}
plot(svmfit, dat)
```


```{r}
table(
  true = dat[-train, "y"],
  pred = predict(tune.out$best.model, newdata = dat[-train, ]) )
```


#a radial kernel
```{r}
svmfit <- svm(y ~ ., data = dat[train, ], kernel = "radial",
              gamma = 1)

set.seed(1)
tune.out <- tune(svm, y ~ ., data = dat[train, ],
                 kernel = "radial",
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000),
                               gamma = c(0.5, 1, 2, 3, 4)
) )
summary(tune.out)
```
```{r}
plot(svmfit, dat)
```

```{r}
table(
  true = dat[-train, "y"],
  pred = predict(tune.out$best.model, newdata = dat[-train, ]) )
```

# techniques performs almost the same


#5.
```{r}
set.seed(12)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
```

```{r}
par(mfrow = c(1, 1))
plot(x1, x2, col =(y+1) , pch = 3-y)
```


#c) Fit a logistic regression model to the data, using X1 and X2 as predictors

```{r}
glm.fits <- glm(y ~ x1 + x2,family = binomial)
summary(glm.fits)
```

#d) Apply this model to the training data
```{r}
glm.probs <- predict(glm.fits, type = "response")
glm.pred <- rep(0, 500)
glm.pred[glm.probs > .5] = 1
table(glm.pred, y)
```
#e) Now fit a logistic regression model to the data using non-linear functions of X1 and X2 as predictors

```{r}
glm.fits1 <- glm(y ~ x1 + I(x1^2) + x2, family = binomial)
summary(glm.fits1)
```
#f) Apply this model to the training data in order to obtain a predicted class label for each training observation.

```{r}
glm.probs1 <- predict(glm.fits1, type = "response")
glm.pred1 <- rep(0, 500)
glm.pred1[glm.probs1 > .5] = 1
table(glm.pred1, y)
```
```{r}
data <- data.frame(x1 = x1, x2 = x2, y = y)
plot(data[glm.pred1 == 1, ]$x1, data[glm.pred1 == 1, ]$x2, col = (1 + 1), pch = (3 - 1), xlab = "X1", ylab = "X2")
points(data[glm.pred1 == 0, ]$x1, data[glm.pred1 == 0, ]$x2, col = (1 + 0), pch = (3 - 0))
```

#g) Fit a support vector classifer to the data with X1 and X2 as predictors.

```{r}
data$y <- as.factor(data$y)
svmfit <- svm(y ~ x1 + x2, data = data, kernel = "linear",
              cost = 0.01, scale = FALSE)
preds <- predict(svmfit, data)
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (1 + 1), pch = (3 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (1 + 0), pch = (3 - 0))
```
#h) Fit a SVM using a non-linear kernel to the data

```{r}
svmfit <- svm(y ~ x1 + x2, data = data, kernel = "radial",
              gamma = 1, cost = 1)
preds <- predict(svmfit, data)
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (1 + 1), pch = (3 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (1 + 0), pch = (3 - 0))
```
#i) Comment on your results.
#fitting a SVM seems best


#6.

#a) Generate two-class data with p = 2


```{r}
set.seed(1)
x <- matrix(rnorm(100 * 2), ncol = 2)
y <- c(rep(-1, 50), rep(1, 50))
x[y == 1, ] <- x[y == 1, ] + 2.5
plot(x, col = (3 - y))
```


#b) Compute the cross-validation error rates for support vector classifers with a range of cost values

```{r}
dat <- data.frame(x = x, y = y)
set.seed(1)
tune.out <- tune(svm, y ~ ., data = dat, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
```

```{r}
summary(tune.out)
```


```{r}
bestmod <- tune.out$best.model
summary(bestmod)
```

#Number of Support Vectors:  87
```{r}
preds <- predict(bestmod, dat)
pred1 <- rep(0, 100)
pred1[preds > .5] = 1
table(pred1, y)
```


#c) Generate an appropriate test data set

```{r}
set.seed(12)
xtest <- matrix(rnorm(50 * 2), ncol = 2)
ytest <- c(rep(-1, 25), rep(1, 25))
xtest[ytest == 1, ] <- xtest[ytest == 1, ] + 2.5
testdat <- data.frame(x = xtest, y = as.factor(ytest))
```


```{r}
costs <- c(0.01, 0.1, 1, 5, 10)
test.err <- rep(NA, length(costs))
data.test <- data.frame(x = xtest, z = as.factor(ytest))
for (i in 1:length(costs)) {
    svmfit <- svm(y ~ ., data = dat, kernel = "linear", cost = costs[i])
    pred <- predict(svmfit, testdat)
    pred1 <- rep(0, 50)
    pred1[pred > .5] = 1
    test.err[i] <- sum(pred1 != testdat$y)
}
data.frame(cost = costs, misclass = test.err)
```
#0.1
#7.
```{r}
Auto <- na.omit(Auto)
Auto$mpg_b <- ifelse(Auto$mpg > median(Auto$mpg), 1, 0)
Auto$mpg_b <-  as.factor(Auto$mpg_b )
```


```{r}
tune.out <- tune(svm, mpg_b ~ .-mpg, data = Auto, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```
#cost = 1


```{r}
bestmod <- tune.out$best.model
summary(bestmod)
ypred <- predict(bestmod, Auto)

table(predict = ypred, truth = Auto$mpg_b)
```
#c) Now repeat (b), this time using SVMs with radial and polynomial basis kernels,
```{r}
tune.out <- tune(svm, mpg_b ~ .-mpg, data = Auto, kernel = "radial",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100),
                               gamma = c(0.5, 1, 2, 3, 4)))
summary(tune.out)

bestmod <- tune.out$best.model
summary(bestmod)
ypred <- predict(bestmod, Auto)

table(predict = ypred, truth = Auto$mpg_b)
```
```{r}
tune.out <- tune(svm, mpg_b ~ .-mpg, data = Auto, kernel = "poly",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100),
                               degree = c(1, 2, 3, 4)))
summary(tune.out)

bestmod <- tune.out$best.model
summary(bestmod)
ypred <- predict(bestmod, Auto)

table(predict = ypred, truth = Auto$mpg_b)
```


```{r}
svm.radial <- svm(mpg_b ~ cylinders + displacement + horsepower + weight + acceleration + year + origin + name, data = Auto,
                  kernel = "radial", cost = 1, gamma = 0.5)
plot(svm.radial, Auto, mpg ~ horsepower)
```

#8.
#a) Create a training set containing a random sample of 800 observations
```{r}
set.seed(1)  
indexes <- sample(1:nrow(OJ), 800)
train <- OJ[indexes, ]
test <- OJ[-indexes, ]
```

```{r}
svmfit <- svm(Purchase ~ ., data = train, kernel = "linear",
              cost = 0.01, scale = FALSE)

summary(svmfit)
```

```{r}
ypred <- predict(svmfit, train)
table(predict = ypred, truth = train$Purchase)
```
#(65+105)/800 =0.2125

```{r}
ypred <- predict(svmfit, test)
table(predict = ypred, truth = test$Purchase)
```
#(20+42)/270 = 0.22962963

#d) Use the tune() function to select an optimal cost. Consider values in the range 0.01 to 10.

```{r}
set.seed(1)
tune.out <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```

```{r}
bestmod <- tune.out$best.model
summary(bestmod)

ypred <- predict(bestmod, train)
table(predict = ypred, truth = train$Purchase)
```

#(69+63)/800 = 0.165
```{r}
ypred <- predict(bestmod, test)
table(predict = ypred, truth = test$Purchase)
```
#(13+31)/270 = 0.162962963

#f) Repeat parts (b) through (e) using a support vector machine with a radial kernel. Use the default value for gamma
```{r}
set.seed(1)
tune.out <- tune(svm, Purchase ~ ., data = train,
                 kernel = "radial",
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000),
                               gamma = c(0.5, 1, 2, 3, 4)
                               ) )
summary(tune.out)
```


```{r}
table(
  true = train$Purchase,
  pred = predict(
    tune.out$best.model, newdata = train
) )
```

#(49+36)/800 = 0.10625

```{r}
table(
  true = test$Purchase,
  pred = predict(
    tune.out$best.model, newdata = test
) )
```
#(37+16)/270 =0.196296296

#g)

```{r}
set.seed(1)
tune.out <- tune(svm, Purchase ~ ., data = train,
                 kernel = "poly",
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000),
                               degree = c(0.5, 1, 2, 3, 4)
                               ) )
summary(tune.out)
```

```{r}
table(
  true = train$Purchase,
  pred = predict(
    tune.out$best.model, newdata = train
) )
```
#(71+61)/800=0.165

```{r}
table(
  true = test$Purchase,
  pred = predict(
    tune.out$best.model, newdata = test
) )
```
#(29+13)/270 = 0.155555556






